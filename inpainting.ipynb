{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCj8Yzeb17pt"
      },
      "source": [
        "# HEINZO Inpainting\n",
        "\n",
        "‚ö†Ô∏è This colab is specifically designed for generating safe and appropriate content, adhering strictly to guidelines for creating family-friendly material. It's not programmed to generate any content that could be considered inappropriate or explicit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDYMvjpcOgU_"
      },
      "source": [
        "# Install\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rc9UGeJj17pu",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title ‚öôÔ∏è 0. Pre-Install (tunggu sampai selesai/crash, baru lanjut play 1. Install Diffuser)\n",
        "!pip install gitpython --quiet\n",
        "from git import Repo\n",
        "full_local_path1 = \"/content/training\"\n",
        "full_local_path2 = \"/content/text\"\n",
        "full_local_path3 = \"/content/initmask\"\n",
        "rain = \"heinzo666\"\n",
        "\n",
        "remote1 = f\"https://{rain}:{summer}@github.com/heinzo666/training.git\"\n",
        "remote2 = f\"https://{rain}:{summer}@github.com/heinzo666/text.git\"\n",
        "remote3 = f\"https://{rain}:{summer}@github.com/heinzo666/initmask.git\"\n",
        "Repo.clone_from(remote1, full_local_path1)\n",
        "Repo.clone_from(remote2, full_local_path2)\n",
        "Repo.clone_from(remote3, full_local_path3)\n",
        "import random\n",
        "import os\n",
        "import shutil\n",
        "!pip install -q diffusers[\"torch\"]\n",
        "!pip install -q git+https://github.com/huggingface/diffusers\n",
        "%cd -q /content/training\n",
        "!pip install -r requirement.txt --quiet\n",
        "%cd /content\n",
        "!mkdir -p /content/images\n",
        "#import random\n",
        "!git clone https://github.com/mikonvergence/ControlNetInpaint --quiet\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ‚öôÔ∏è 1. Install Diffuser\n",
        "from git import Repo\n",
        "import random\n",
        "first_names=('Shani','Gita','Azizi','Cornelia','Marsha','Gabriela','Greesella')\n",
        "last_names=('Indira','Sekar','Asadel','Vanisa','Lenathea','Abigail','Adhalia')\n",
        "user=random.choice(first_names)+random.choice(last_names)\n",
        "#!git clone https://github.com/heinzo666/training.git --quiet\n",
        "!git config --global user.email \"email@gmail.com\"\n",
        "!git config --global user.name {user}\n",
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "sys.path.append('./ControlNetInpaint/')\n",
        "from diffusers import StableDiffusionInpaintPipeline, ControlNetModel\n",
        "# from src.pipeline_stable_diffusion_controlnet_inpaint import *\n",
        "from diffusers.utils import load_image, make_image_grid\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "import PIL\n",
        "import gradio as gr\n",
        "import subprocess\n",
        "#import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import requests\n",
        "import numpy as np\n",
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import Javascript\n",
        "import ipywidgets as widgets\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 200})'''))\n",
        "def inf(msg, style, wdth): inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth));display(inf)\n",
        "\n",
        "\n",
        "controlnet = ControlNetModel.from_pretrained(\n",
        "    \"lllyasviel/sd-controlnet-openpose\", torch_dtype=torch.float16\n",
        ")\n",
        "#model_id_or_path = \"Uminosachi/realisticVisionV51_v51VAE-inpainting\" # @param [\"Uminosachi/realisticVisionV51_v51VAE-inpainting\", \"emilianJR/chilloutmix_NiPrunedFp32Fix\", \"suridov/uber-realistic-porn-merge-urpm_with_files\"] {allow-input: true}\n",
        "model_id_or_path = \"Uminosachi/realisticVisionV51_v51VAE-inpainting\"\n",
        "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
        "     model_id_or_path, controlnet=controlnet, torch_dtype=torch.float16\n",
        " )\n",
        "pipe = pipe.to(\"cuda\")\n",
        "pipe.safety_checker = None\n",
        "#from diffusers import UniPCMultistepScheduler\n",
        "#pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "from diffusers import DPMSolverMultistepScheduler\n",
        "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "pipe.enable_sequential_cpu_offload()\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "\n",
        "!git clone https://huggingface.co/nemesis1/embeddings\n",
        "pipe.load_textual_inversion(\"/content/embeddings/bad-hands-5.pt\", token=\"bad_hands5\")\n",
        "pipe.load_textual_inversion(\"/content/embeddings/negative_hand-neg.pt\", token=\"negative_hands\")\n",
        "pipe.load_textual_inversion(\"/content/embeddings/breasts.pt\", token=\"breastAI\")\n",
        "pipe.load_textual_inversion(\"/content/embeddings/ulzzang-6500.pt\", token=\"ulzzang-6500\")\n",
        "pipe.load_textual_inversion(\"/content/embeddings/bukkakAI.pt\", token=\"bukkaAI\")\n",
        "\n",
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(\"HOME:\", HOME)\n",
        "!pip install -q 'git+https://github.com/heinzo666/mas.git'\n",
        "!pip install -q jupyter_bbox_widget roboflow dataclasses-json supervision\n",
        "!mkdir -p {HOME}/weights\n",
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -P {HOME}/weights\n",
        "import os\n",
        "\n",
        "CHECKPOINT_PATH = os.path.join(HOME, \"weights\", \"sam_vit_h_4b8939.pth\")\n",
        "print(CHECKPOINT_PATH, \"; exist:\", os.path.isfile(CHECKPOINT_PATH))\n",
        "import torch\n",
        "\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "MODEL_TYPE = \"vit_h\"\n",
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
        "\n",
        "sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)\n",
        "mask_predictor = SamPredictor(sam)\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4-4vquwvSBut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPSUXdCEvqwC"
      },
      "source": [
        "# Making & Import mask\n",
        "<!-- -Tekan Play\n",
        "\n",
        "-Upload image\n",
        "\n",
        "-Buat mask dengan brush\n",
        "\n",
        "-Tekan submit\n",
        "\n",
        "-Tekan Stop\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "![model1](https://drive.google.com/uc?export=view&id=1GEU28js34csA_C_YhSv6ZWO54YfQ-WOQ)\n",
        "\n",
        "![model1](https://drive.google.com/uc?export=view&id=179SECTN-2kztZ90LoEr-rr7Y-jja85Hi)\n",
        "\n",
        "\n",
        "--- -->\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Bno7EhOJ9uF",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# @title üì• 2. Input\n",
        "\n",
        "# @markdown Pilih Auto-masking atau dengan Brush\n",
        "\n",
        "masking = \"Auto\" # @param [\"Brush\", \"Auto\"]\n",
        "selected_pixels = []\n",
        "if masking == \"Brush\":\n",
        "  with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"Buat masking dengan brush\")\n",
        "    with gr.Row():\n",
        "       input_brush = gr.Image(label=\"Input\", source = 'upload', tool = \"sketch\", type = 'pil')\n",
        "       mask_brush = gr.Image(label=\"Mask\")\n",
        "    with gr.Row():\n",
        "       submit = gr.Button(\"Submit\")\n",
        "    def predict(dict):\n",
        "       image =  dict['image'].convert(\"RGB\")\n",
        "       mask_image = dict['mask'].convert(\"RGB\")\n",
        "       image.save(\"/content/init.png\")\n",
        "       mask_image.save(\"/content/mask.png\")\n",
        "       return(mask_image)\n",
        "    submit.click(\n",
        "       predict,\n",
        "       inputs=[input_brush],\n",
        "       outputs=[mask_brush],\n",
        "       )\n",
        "  if __name__ == \"__main__\":\n",
        "    demo.launch()\n",
        "\n",
        "else:\n",
        "  with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"Buat auto masking dengan klik pada gambar\")\n",
        "    with gr.Row():\n",
        "       input_img = gr.Image(label=\"Input\")\n",
        "       mask_img = gr.Image(label=\"Mask\")\n",
        "\n",
        "    def generate_mask(image, evt: gr.SelectData):\n",
        "        selected_pixels.append(evt.index)\n",
        "\n",
        "        mask_predictor.set_image(image)\n",
        "        input_points = np.array(selected_pixels)\n",
        "        input_labels = np.ones(input_points.shape[0])\n",
        "        mask, _, _ = mask_predictor.predict(\n",
        "            point_coords=input_points,\n",
        "            point_labels=input_labels,\n",
        "            multimask_output=True\n",
        "        )\n",
        "        image = Image.fromarray(image)\n",
        "        mask = Image.fromarray(mask[1, :, :])\n",
        "        image.save(\"/content/init.png\")\n",
        "        mask.save(\"/content/mask.png\")\n",
        "        return mask\n",
        "\n",
        "    input_img.select(generate_mask, [input_img], [mask_img])\n",
        "  if __name__ == \"__main__\":\n",
        "    demo.launch()\n",
        "\n",
        "\n",
        "\n",
        "#).launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eVOgnhPgvqwO"
      },
      "outputs": [],
      "source": [
        "\n",
        "# @title üì• 3. Set mask blur, & ControlNet\n",
        "# @markdown Init Image, Mask Image, ControlNet\n",
        "\n",
        "%cd -q /content/initmask\n",
        "!git pull -q\n",
        "!python import.py\n",
        "%cd -q /content\n",
        "from controlnet_aux import OpenposeDetector\n",
        "\n",
        "openpose = OpenposeDetector.from_pretrained('lllyasviel/ControlNet')\n",
        "\n",
        "image_url = \"/content/init.png\"\n",
        "mask_url = \"/content/mask.png\"\n",
        "\n",
        "init_image = load_image(image_url)\n",
        "mask = load_image(mask_url)\n",
        "pose_image = openpose(init_image)\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown Radius blur mask\n",
        "blur = 15 # @param {type:\"slider\", min:0, max:100, step:1}\n",
        "mask_image = pipe.mask_processor.blur(mask, blur_factor=blur)\n",
        "init_image=init_image.resize(pose_image.size)\n",
        "mask_image=mask_image.resize(pose_image.size)\n",
        "mask_image_array = np.array(mask_image)\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown Radius offset mask. Makin besar, makin melebar.\n",
        "kernel_size = 10 # @param {type:\"slider\", min:0, max:100, step:1}\n",
        "kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
        "dilated_mask = cv2.dilate(mask_image_array, kernel, iterations=1)\n",
        "mask_image = Image.fromarray(dilated_mask)\n",
        "make_image_grid([init_image, mask_image, pose_image], rows=1, cols=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBIgqL7OPDO3"
      },
      "source": [
        "# Training\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KoII2Xa17pw",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        " # @title ü§ñ 4. Parameters\n",
        "\n",
        "# @markdown ---\n",
        "# markdown Prompt\n",
        "tx = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
        "pipe.unload_lora_weights()\n",
        "\n",
        "# @markdown Text atau informasi untuk prompt A.I.\n",
        "prompt = \"(8k, RAW photo, best quality, masterpiece:1.2), (realistic, photo-realistic:1.37), 1girl, slim, nude, topless, professional lighting, radiosity, physically-based rendering, ulzzang-6500, breastAI, \" # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown Text atau informasi yang tidak boleh disertakan dalam training.\n",
        "negative_prompt = \"clothes, clothing, paintings, sketches, (worst quality:2), (low quality:2), (normal quality:2), lowres, normal quality, ((monochrome)), ((grayscale)), ( clenched teeth,  ), skin spots, acnes, skin blemishes, age spot, bad anatomy, ugly face, deformed features, derp face, bad eyes, negative_hands, bad_hands5,\" # @param {type:\"string\"}\n",
        "height = (pose_image.height)\n",
        "width = (pose_image.width)\n",
        "height_hd = (pose_image.height)*2\n",
        "width_hd = (pose_image.width)*2\n",
        "# markdown ---\n",
        "# markdown Parameters\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown Jumlah langkah training. Semakin besar, semakin berkualitas tetapi semakin lambat.\n",
        "steps = 25 # @param {type:\"slider\", min:1, max:100, step:1}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown Jumlah langkah panduan prompt. Semakin besar, semakin dekat dengan prompt dengan mengorbankan kualitas.\n",
        "guidance = 7 # @param {type:\"slider\", min:1, max:25, step:0.5}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown Kemiripan dengan gambar awal. 0.1 = tidak banyak berubah\n",
        "denoising_strength = 1 # @param {type:\"slider\", min:0.1, max:1, step:0.05}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown Jumlah images per training\n",
        "num_images = 2 # @param {type:\"number\"}\n",
        "# seed = 7178789992 # @param {type:\"number\"}\n",
        "# generator = torch.Generator(device=\"cuda\").manual_seed(seed)\n",
        "# @markdown ---\n",
        "# @markdown LoRa\n",
        "\n",
        "# @markdown LoRa membantu apa yang susah dilakukan prompt. (set lora_weight ke 0 jika tidak ingin memakai Lora)\n",
        "lora_path = \"nemesis1/breastinclassbetter_v141\" # @param [\"nemesis1/oversizedshirt\", \"nemesis1/betterbody\", \"nemesis1/hourglassbody\", \"nemesis1/breastinclassbetter_v141\", \"nemesis1/cumshot\", \"nemesis1/cohf\", \"nemesis1/skirtlift\", \"nemesis1/ShirtLift\", \"nemesis1/calvinklein\", \"nemesis1/sm\", \"nemesis1/croptop_underboob\", \"nemesis1/bikini_micro\", \"nemesis1/bikini_1\", \"nemesis1/bikini_underboob\", \"nemesis1/bikini_furcoat\", \"nemesis1/onoff_v4\", \"nemesis1/nipples\"] {allow-input: true}\n",
        "pipe.load_lora_weights(lora_path)\n",
        "lora_weight = 0.5 # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "text = ('/content/text/outputs/P' + str(tx) +'.txt')\n",
        "with open(text, \"w\") as tt:\n",
        "   print(f\"{prompt}\",  file=tt)\n",
        "   print(f\"{negative_prompt}\",  file=tt)\n",
        "   print(f\"{steps}, {guidance}, {denoising_strength}, {lora_weight}, {lora_path}\", file=tt)\n",
        "logtxt = ('/content/training/l' + str(user) +'.txt')\n",
        "def git_pull_and_log():\n",
        "    try:\n",
        "        # Run the git pull command and capture output\n",
        "        result = subprocess.run(['git', 'pull'], capture_output=True, text=True, check=True)\n",
        "\n",
        "        # Log success message to the file\n",
        "        with open(logtxt, \"w\") as tt:\n",
        "            print(\"Git pull successful.\", file=tt)\n",
        "            print(result.stdout.strip(), file=tt)  # Log the output of the command\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        # Log error message to the file\n",
        "        with open(logtxt, \"w\") as tt:\n",
        "            print(\"Git pull failed.\", file=tt)\n",
        "            print(e.stderr.strip(), file=tt)  # Log the error output\n",
        "%cd -q /content/text\n",
        "!git pull -q\n",
        "!python training.py\n",
        "%cd -q /content\n",
        "\n",
        "# @markdown ---\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xV_ogLEoX999"
      },
      "outputs": [],
      "source": [
        "\n",
        "# @title ü§ñ 5. Training (Play lagi untuk generate image baru)\n",
        "tgl = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
        "images = pipe(prompt=prompt, negative_prompt=negative_prompt, image=init_image, control_image=pose_image, mask_image=mask_image, cross_attention_kwargs={\"scale\": lora_weight}, height=height, width=width, num_inference_steps=steps, guidance_scale=guidance, num_images_per_prompt=num_images, strength=denoising_strength,).images\n",
        "for i in range(num_images):\n",
        "  original_image_array = np.array(init_image)\n",
        "  generated_image_array = np.array(images[i])\n",
        "  mask_image_array = np.array(mask_image)\n",
        "  mask_image_inverted = cv2.bitwise_not(mask_image_array)\n",
        "  converted_image_array = np.where(\n",
        "        mask_image_inverted == 255, original_image_array, generated_image_array\n",
        "    )\n",
        "  converted_image = Image.fromarray(converted_image_array)\n",
        "\n",
        "  display(converted_image)\n",
        "  converted_image.save('/content/images/HEINZO' + str(tgl) + str(i) + '.png')\n",
        "  converted_image.save('/content/training/outputs/H' + str(tgl) + str(i) + '.png')\n",
        "%cd -q /content/training\n",
        "!git stash -q\n",
        "git_pull_and_log()\n",
        "!git stash apply -q\n",
        "full_local_path = \"/content/training\"\n",
        "repo = Repo(full_local_path)\n",
        "repo.git.add(\"-A\")\n",
        "repo.index.commit(tgl)\n",
        "origin = repo.remote(name=\"origin\")\n",
        "origin.push()\n",
        "%cd -q /content"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üñºÔ∏è 6. Output Gallery\n",
        "image_folder = '/content/images'\n",
        "\n",
        "image_files = sorted(\n",
        "    [os.path.join(image_folder, file) for file in os.listdir(image_folder) if file.endswith(('png', 'jpg', 'jpeg'))],\n",
        "    key=os.path.getmtime,\n",
        "    reverse=True\n",
        ")\n",
        "\n",
        "# Create the Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "        # Create a gallery to display image thumbnails\n",
        "        gallery = gr.Gallery(value=image_files, label=\"Image Gallery\")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "demo.launch()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2czAM8_4n5Yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @title ‚¨áÔ∏è 7. Download all images as rar (cukup sekali diakhir)\n",
        "!zip -r /content/Heinzo_Inpainting.rar /content/images\n",
        "from google.colab import files\n",
        "files.download(\"/content/Heinzo_Inpainting.rar\")\n",
        "%cd training\n",
        "!git pull -q\n",
        "!python download.py\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "p3-KApZtZivY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}